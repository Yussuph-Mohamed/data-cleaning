---
title: "Titanic dataset: Data cleaning and validation"
author: "Jesús Ros Solé"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_libraries, include=FALSE}
library(knitr)
library(VIM)
```

# 1. Dataset description

This dataset has been obtained from the Kaggle competition [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic) and contains a set of atributes for each of the passengers boarding the Titanic in the day of its accident. 

It contains two datasets: a training dataset to build models with and a test dataset to perform predictions on. The training dataset has information on 891 passengers (rows) and 12 attributes (columns) while the test dataset has 418 passengers and 11 attributes (minus the target attribute `Survived`).

The attribute descriptions are:

- *PassengerID*: an integer identifier for each passenger.
- *Survived*: target class encoded as `1` (survived) or `0` (not survived). Missing in test set.
- *Pclass*: boarding class encoded as `1` (first class), `2` (second class) or `3` (third class).
- *Name*: name of the passenger as a string.
- *Sex*: sex of the passenger encoded as `male` or `female`.
- *Age*: age of the passenger,
- *SibSp*: number of siblings/spouse aboard.
- *Parch*: number of parent/child aboard.
- *Ticket*: identifier of the boarding pass.
- *Fare*: ticket fare amount.
- *Cabin*: identifier of the passenger cabin.
- *Embarked*: identifier for the port in which the passenger embarked encoded as `C` (Cherbourg), `S` (Southampton) and `Q` (Queenstown).

The objective of this work is study the groups of people that are more likely to survive according to the given attributes and to predict the survival chances of the people in the test set.

# 2. Data integration and selection

First we will load the training and test set using `read.csv` indicating the corresponding data types. We then extract the target attribute from the test set and merge the training and test datasets for the next steps.

```{r load}
train <- read.csv("../data/raw/train.csv", 
                  colClasses=c("integer", "factor" ,"factor" ,"character" ,"factor"
                               ,"numeric" ,"integer" ,"integer" ,"character" ,"numeric"
                               ,"character" ,"factor"), 
                  na.strings = c("NA", ""))
test <- read.csv("../data/raw/test.csv", 
                 colClasses=c("integer" ,"factor" ,"character" ,"factor" ,"numeric"
                              ,"integer" ,"integer" ,"character" ,"numeric"
                              ,"character" ,"factor"), 
                 na.strings = c("NA", ""))

y_train <- train["Survived"]
train$Survived <- NULL

all <- rbind(train, test)
```

Now that we have our data properly loaded, we will select the attributes that are going to be useful for the posterior analysis. First note that the `PassengerID` and `Ticket` attributes will not yield much information to our analysis since they are mostly unique identifiers and can thus be ignored. The `Name` attribute by itself will not be very informative either, but we can extract the passenger title from it.

```{r title}
all$Title <- gsub("^.*, (.*?)\\..*$","\\1",all$Name)
table(all$Title)
```

By looking at the obtained titles we can see that `Master`, `Miss`, `Mr` and `Mrs` are the most common while the others are quite rare. We will try to aggregate some of them to the most common ones (for instance `Ms` is a different spelling from `Miss`) and create an additional class for the rest.

```{r title2}
all$Title[all$Title %in% c("Mlle", "Ms")] <- "Miss"
all$Title[!(all$Title %in% c('Master', 'Miss', 'Mr', 'Mrs'))] <- "Other"
table(all$Title)
all$Title <- as.factor(all$Title)
```

Additinally, we can create a new variable indicating the family size aboard the Titanic from the `SibSp` and `Parch` attributes.

```{r family}
all$FamilySize <- all$SibSp+all$Parch+1 #includes self
```

Now we can drop the variables that yield no information `PassengerId`, `Name` and `Ticket`.

```{r drop1}
drop <- c("PassengerId", "Name", "Ticket")
all <- all[, !(names(all) %in% drop)]
```

# 3. Data cleaning

At this point, we have selected the attributes that will be useful for our posterior analysis and have created a couple new derived attributes from our dataset. Now we will inspect the remaining attributes for empty values that need to be taken care of.

```{r empty}
count_empty <- function(attr){sum(is.na(attr))}
sapply(all,count_empty)
```

We observed that the `Cabin` attribute contains mostly empty elements, in fact, about 77% of the rows contain missing data. Therefore, this attribute can be ignored since it will not yield much information. The other attributes that contain missing data are `Age`, `Fare` and `Embarked`. We will use kNN imputation with default settings after dropping the `Cabin` column.

```{r imput}
all$Cabin <- NULL
all_clean <- suppressWarnings(kNN(all,imp_var=FALSE))
sapply(all_clean,count_empty)
```

Next we will investigate the extreme values in the dataset for numeric attributes. Numeric attributes are `Age`, `SibSp`, `Parch`, `Fare` and `FamilySize`. Since `FamilySize` is derived from `SibSp` and `Parch` we will only investigate `Age`, `Fare` and `FamilySize` using a boxplot.

```{r outliers}
par(mfrow=c(1,3))
boxplot(all_clean$Age, main="Age")
boxplot(all_clean$Fare, main="Fare")
boxplot(all_clean$FamilySize, main="FamilySize")
```

We observe some outliers in all 3 variables but their values seem to be realistic. We have ages up to 80 years, fares up to 500 dollars and families of up to 11 members. Therefore we decide to leave the outliers as is.

Finally, we have a clean dataset for further analysis. We will export the clean dataset to a datafile, respecting the initial traning and test partition and adding the target attribute to the training file.

```{r export}
train <- cbind(all_clean[1:nrow(train),],y_train)
test <- all_clean[(nrow(train)+1):nrow(all_clean),]
write.csv(train, "../data/clean/train.csv", row.names=F)
write.csv(test, "../data/clean/test.csv", row.names=F)
```

# 4. Data analysis
